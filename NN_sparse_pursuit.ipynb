{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_sparse_pursuit.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMb9qERRM0zPa1MM7mK5nUc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsachiblau/sparseGANProject/blob/master/NN_sparse_pursuit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aokrzvz7U4fm",
        "colab_type": "text"
      },
      "source": [
        "This notebook contains implementation of sparse representation pursuit using NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owhk6qUmVM2k",
        "colab_type": "text"
      },
      "source": [
        "Set up & load data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIctqJsfU3NR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "7ef0c394-9972-47e5-a9d2-53e6a64395b7"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# setting up params\n",
        "np.random.seed(10)\n",
        "noise_dim = 100\n",
        "batch_size = 16\n",
        "half_batch_size = int(batch_size/2)\n",
        "steps_per_epoch = 3750  # batch_size * steps_per_epoch = epoch size (train size)\n",
        "epochs = 5\n",
        "img_rows, img_cols, channels = 28, 28, 1\n",
        "sparse_dim = img_rows * img_cols * channels\n",
        "load_dict = True\n",
        "# loss functions weight:\n",
        "L1_weight = 10   # Loss = data_fidelity + L1_weight * L1_norm\n",
        "thr_value = 0.1\n",
        "# optimizer - lr & beta are hyper parameters\n",
        "optimizer = Adam(0.0002,0.5) \n",
        "#load data set\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = (x_train.astype(np.float32) - 127.5) / 127.5  # normalize between +1 -1\n",
        "x_train = x_train.reshape(-1, img_rows*img_cols*channels) # each image as vector\n",
        "x_test = x_test.reshape(-1, img_rows*img_cols*channels) # each image as vector\n",
        "np.random.shuffle(x_train)\n",
        "print(x_train.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48F-P2pVVbt3",
        "colab_type": "text"
      },
      "source": [
        "get dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgAUPHJCVddX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "7b1b51a3-9185-45d9-b669-1a5355367f63"
      },
      "source": [
        "from sklearn.decomposition import DictionaryLearning\n",
        "from numpy import loadtxt,savetxt\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from numpy import loadtxt,savetxt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if(load_dict==False):\n",
        "  # init a dictionary learning alg - based on LARS\n",
        "  d=DictionaryLearning(n_components=sparse_dim)\n",
        "  # train dictionary\n",
        "  d.fit(x_train)\n",
        "  dictionary = d.components_\n",
        "  savetxt('dictionary.csv', dictionary, delimiter=',')\n",
        "  # download to local machine\n",
        "  files.download('dictionary.csv') \n",
        "\n",
        "  # we will download to a local file named dictionary_loaded\n",
        "  #*reconstruct* an image for sanity check\n",
        "  representation_vec = d.transform(x_train[1:2,:])\n",
        "  print(representation_vec.shape)\n",
        "  print(dictionary_loaded2.shape)\n",
        "  dictionary_loaded2 = np.transpose(dictionary_loaded2)\n",
        "  representation_vec = np.transpose(representation_vec)\n",
        "  ans = np.matmul(dictionary_loaded2,representation_vec)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(ans.reshape((img_rows, img_cols)), cmap='gray')\n",
        "\n",
        "  plt.figure()\n",
        "  real_im = x_train[1:2,:]\n",
        "  plt.imshow(real_im.reshape((img_rows, img_cols)), cmap='gray')\n",
        "else:\n",
        "  dictionary_loaded2 = loadtxt('dictionary_loaded.csv', delimiter=',')\n",
        "  dictionary_loaded2 = np.array(dictionary_loaded2,dtype=np.float32) # format that is used in keras\n",
        "  # the above dict should enable training a regular gan\n",
        "\n",
        "  # sanity check\n",
        "  dictionary_loaded2 = np.transpose(dictionary_loaded2)\n",
        "  atom1 = (dictionary_loaded2)[:,0]\n",
        "  plt.figure()\n",
        "  plt.imshow(atom1.reshape((img_rows, img_cols)), cmap='gray')\n",
        "\n",
        "  first_atom = np.zeros(784)\n",
        "  first_atom[0] = 1\n",
        "  plt.figure()\n",
        "  ans = np.matmul(dictionary_loaded2,np.transpose(first_atom))\n",
        "  plt.imshow(ans.reshape((img_rows, img_cols)), cmap='gray')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRB2IAnCDiRB2IEkCDuQBGEHkvh/kvnsjcCtq7gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRB2IAnCDiRB2IEkCDuQBGEHkvh/kvnsjcCtq7gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmQ8XQsYVwOc",
        "colab_type": "text"
      },
      "source": [
        "Creating pursuiter NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iXfxG3OV-Iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "outputId": "a18bc9d0-af44-4c9c-db97-02832c6bbde2"
      },
      "source": [
        "# with pursuit and thresholding approach\n",
        "# generator:\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.initializers import RandomNormal, glorot_uniform\n",
        "from keras.layers import Dense, Conv2D, Flatten, Reshape, Dropout, AveragePooling2D, MaxPooling2D, BatchNormalization, Lambda, ReLU, ThresholdedReLU, Activation\n",
        "from tensorflow.linalg import matmul, matrix_transpose\n",
        "from tensorflow.math import abs\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "import tensorflow as tf\n",
        "from tensorflow import cast\n",
        "\n",
        "# would cause small entries in absulute values to be set to zero and will create sparse vectors\n",
        "def soft_threshlding(x):\n",
        "  above_thr_pos = x * cast(x >= thr_value, tf.float32)\n",
        "  below_thr_neg = x * cast(x <= -thr_value, tf.float32)\n",
        "  return (above_thr_pos + below_thr_neg)\n",
        "\n",
        "get_custom_objects().update({'soft_threshlding': Activation(soft_threshlding)})\n",
        "\n",
        "def create_pursuiter():\n",
        "    pursuiter = Sequential()\n",
        "    init = RandomNormal(0,stddev=0.02)\n",
        "    pursuiter.add(Dense(1024, kernel_initializer=init, input_dim=784,name=\"pursuiter_input\"))\n",
        "    pursuiter.add(BatchNormalization())\n",
        "    pursuiter.add(LeakyReLU(0.2))\n",
        "\n",
        "    pursuiter.add(Dense(1024,kernel_initializer=init,name=\"pursuiter_2nd\"))\n",
        "    pursuiter.add(BatchNormalization())\n",
        "    pursuiter.add(LeakyReLU(0.2))\n",
        "\n",
        "    pursuiter.add(Dense(sparse_dim, kernel_initializer=init,name=\"pursuiter_3rd\"))\n",
        "    pursuiter.add(BatchNormalization())\n",
        "    # soft thresholding activation\n",
        "    pursuiter.add(Activation(soft_threshlding, name='soft_threshlding'))\n",
        "\n",
        "    #pursuiter.add(Lambda(lambda x: matrix_transpose(matmul(dictionary_loaded2,matrix_transpose(x))),name='mul_in_D'))\n",
        "\n",
        "    #pursuiter.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "    return pursuiter\n",
        "\n",
        "pursuiter = create_pursuiter()\n",
        "pursuiter.name = \"pursuit_unit\"\n",
        "pursuiter_input = Input(shape=(784,))\n",
        "\n",
        "sparse_vec = pursuiter(pursuiter_input) \n",
        "\n",
        "# a layer that creates the multiplication between the sparse tensor with dictionary to create image\n",
        "fake_image_vec = Lambda(lambda x: matrix_transpose(matmul(dictionary_loaded2,matrix_transpose(x))),name='mul_in_D')(sparse_vec)\n",
        "\n",
        "\n",
        "pursuiter_full = Model(pursuiter_input, [fake_image_vec,sparse_vec])\n",
        "pursuiter_full.compile(loss=['mean_squared_error','mean_absolute_error'], optimizer=optimizer,loss_weights=[1,L1_weight])\n",
        "pursuiter_full.name = \"pursuiter_full\"\n",
        "print(pursuiter_full.summary())\n",
        "\n",
        "#train\n",
        "zeros = np.zeros(10000*784)\n",
        "zeros=zeros.reshape(10000,784)\n",
        "model1=pursuiter_full.fit(x_train, [x_train,x_train], validation_data=(x_test, [x_test,zeros]), epochs=epochs, batch_size=16)\n",
        "\n",
        "plot_model(pursuiter_full, to_file='model_plot.png', show_shapes=True, show_layer_names=True,expand_nested=True)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "print(model1.history)\n",
        "plt.plot(range(1,len(model1.history['loss'])+1),model1.history['loss'], label='Train Acc')\n",
        "plt.plot(range(1,len(model1.history['val_loss'])+1),model1.history['val_loss'], label='Test Acc')\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"pursuiter_full\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "pursuit_unit (Sequential)    (None, 784)               2668368   \n",
            "_________________________________________________________________\n",
            "mul_in_D (Lambda)            (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 2,668,368\n",
            "Trainable params: 2,662,704\n",
            "Non-trainable params: 5,664\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "21904/60000 [=========>....................] - ETA: 1:38 - loss: 8.2078 - mul_in_D_loss: 0.2937 - pursuit_unit_loss: 0.7914"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrU_M9SpWGJ8",
        "colab_type": "text"
      },
      "source": [
        "analyse results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X84fgUcEWJZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "x_train_pred = pursuiter.predict(x_train)\n",
        "print(\"average support on train= \", np.count_nonzero(x_train_pred)/60000)\n",
        "\n",
        "x_test_pred = pursuiter.predict(x_test)\n",
        "print(\"average support on test= \", np.count_nonzero(x_test_pred)/10000)\n",
        "\n",
        "im = random.randrange(0, 9999)\n",
        "x_train.shape\n",
        "x = np.array([x_test[im,:]])\n",
        "\n",
        "# plt results\n",
        "print(\"Im_r, Im\")\n",
        "plt.figure()\n",
        "plt.imshow(pursuiter_full.predict(x)[0].reshape((img_rows, img_cols)), cmap='gray')\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(x[0].reshape((img_rows, img_cols)), cmap='gray')\n",
        "\n",
        "# is it sparse?\n",
        "pred = pursuiter.predict(x)\n",
        "print(\"sparse vector dim = \", pred.shape)\n",
        "print(\"sparse vector non zeros = \", np.count_nonzero(pred))\n",
        "print(\"sparse vec max element is = \",np.max(pred))\n",
        "print(\"positive number = \", np.count_nonzero(pred[pred>0]))\n",
        "print(\"sparse vec average positive =\",np.mean(pred[pred>0]))\n",
        "print(\"negatives number = \", np.count_nonzero(pred[pred<0]))\n",
        "print(\"sparse vec average negative =\",np.mean(pred[pred<0]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}