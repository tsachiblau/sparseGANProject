{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FCG_2_CND.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmojFwdj/dZDRZpdJcTpLf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsachiblau/sparseGANProject/blob/master/FCG_2_CND.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkK1DYV4fAjr",
        "colab_type": "text"
      },
      "source": [
        "Setting up environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiKP4Zgfe5Lj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "9fd3e0a5-68db-41a1-aba4-bd3097aa2309"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(10)\n",
        "\n",
        "noise_dim = 100\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "steps_per_epoch = 3750  # batch_size * steps_per_epoch = epoch size (train size)\n",
        "epochs = 10\n",
        "\n",
        "img_rows, img_cols, channels = 28, 28, 1\n",
        "sparse_dim = img_rows * img_cols * channels\n",
        "#sparse_dim = 10\n",
        "optimizer = Adam(0.0002, 0.5)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhwQIIKyfHQX",
        "colab_type": "text"
      },
      "source": [
        "importing the data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1583sxTfJ6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a3b2a0d1-a109-41d0-ba76-f7e7d5d47b9c"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = (x_train.astype(np.float32) - 127.5) / 127.5  # normalize between +1 -1\n",
        "\n",
        "x_train = x_train.reshape(-1, img_rows*img_cols*channels) # each image as vector\n",
        "\n",
        "np.random.shuffle(x_train)\n",
        "print(x_train.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L18sEjMcfMCi",
        "colab_type": "text"
      },
      "source": [
        "Build FC generator CN discriminator with reconstructor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk8JsyBCfQw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "03d987c0-9a55-4579-f5a7-0621fec62553"
      },
      "source": [
        "# generator:\n",
        "from keras.models import Sequential\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.layers import Dense, Conv2D, Flatten, Reshape, Dropout, AveragePooling2D, MaxPooling2D, BatchNormalization\n",
        "\n",
        "# input: image size\n",
        "# output: noise size\n",
        "def create_reconstructor():\n",
        "    reconstructor = Sequential()\n",
        "\n",
        "    reconstructor.add(Dense(512, input_dim=img_cols*img_rows*channels))\n",
        "    reconstructor.add(LeakyReLU(0.2))\n",
        "\n",
        "    reconstructor.add(Dense(256))\n",
        "    reconstructor.add(LeakyReLU(0.2))\n",
        "\n",
        "    reconstructor.add(Dense(noise_dim))\n",
        "    reconstructor.add(LeakyReLU(0.2))\n",
        "\n",
        "    #reconstructor.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "    return reconstructor\n",
        "\n",
        "# input: noise size\n",
        "# output: image size\n",
        "def create_generator():\n",
        "    generator = Sequential()\n",
        "    \n",
        "    generator.add(Dense(256, input_dim=noise_dim))\n",
        "    generator.add(BatchNormalization())\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(512))\n",
        "    generator.add(BatchNormalization())\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(1024))\n",
        "    generator.add(BatchNormalization())\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(img_rows*img_cols*channels, activation='tanh'))\n",
        "    # remove this to return to FC scheme\n",
        "    generator.add(Reshape((img_rows, img_cols, channels)))\n",
        "    #generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    return generator\n",
        "\n",
        "# input: image size\n",
        "# output: 1 number - 1 real 0 fake\n",
        "# descriminator:\n",
        "def create_descriminator():\n",
        "    discriminator = Sequential()\n",
        "    #16 - better\n",
        "    discriminator.add(Conv2D(16, (3, 3), strides=(2,2),padding='same', kernel_initializer=RandomNormal(0, 0.02), input_shape=(img_cols, img_rows, channels)))\n",
        "    discriminator.add(BatchNormalization())\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    #32 - better\n",
        "    discriminator.add(Conv2D(32, (3, 3), strides=(2,2), padding='same', kernel_initializer=RandomNormal(0, 0.02)))\n",
        "    discriminator.add(BatchNormalization())\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    # 64 - better\n",
        "    discriminator.add(Conv2D(64, (3, 3), strides=(2,2), padding='same', kernel_initializer=RandomNormal(0, 0.02)))\n",
        "    discriminator.add(BatchNormalization())\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    \n",
        "    discriminator.add(Flatten())\n",
        "    discriminator.add(Dropout(0.4))\n",
        "    discriminator.add(Dense(1, activation='sigmoid'))   # 1 number which indicates real / fake\n",
        "    \n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    return discriminator\n",
        "    \n",
        "\"\"\"\n",
        "def create_descriminator():\n",
        "    discriminator = Sequential()\n",
        "     \n",
        "    discriminator.add(Dense(1024, input_dim=img_rows*img_cols*channels))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Dense(512))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Dense(256))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    \n",
        "    discriminator.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    return discriminator\n",
        "\"\"\"\n",
        "# build GAN\n",
        "discriminator = create_descriminator()\n",
        "generator = create_generator()\n",
        "reconstructor = create_reconstructor()\n",
        "\n",
        "discriminator.trainable = False   # will be trained separately, not as GAN\n",
        "\n",
        "gan_input = Input(shape=(noise_dim,))\n",
        "\n",
        "fake_image = generator(gan_input)\n",
        "\n",
        "fake_image_vec = Flatten()(fake_image)  # will enter reconstructor\n",
        "\n",
        "\n",
        "gan_output = discriminator(fake_image)\n",
        "\n",
        "vae_output = reconstructor(fake_image_vec)\n",
        "\n",
        "vae = Model(gan_input, vae_output)\n",
        "vae.compile(loss='mean_squared_error', optimizer='sgd') #todo: consider MAE\n",
        "\n",
        "\n",
        "gan = Model(gan_input, gan_output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt0-f-RufX8t",
        "colab_type": "text"
      },
      "source": [
        "Train the GAN model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMzNUrkBfaW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17d3d010-aa33-461f-d459-f71478345890"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    for batch in range(steps_per_epoch): \n",
        "        noise = np.random.normal(0, 1, size=(batch_size, noise_dim))  # will generate batch amount of noise vectors (gaussian distribution)\n",
        "        fake_x = generator.predict(noise) # create G(z)\n",
        "\n",
        "        real_x = x_train[np.random.randint(0, x_train.shape[0], size=batch_size)] # sample real image\n",
        "        #remove below to return to FC scheme\n",
        "        real_x = real_x.reshape(fake_x.shape)\n",
        "\n",
        "        x = np.concatenate((real_x, fake_x))\n",
        "\n",
        "        disc_y = np.zeros(2*batch_size)\n",
        "        disc_y[:batch_size] = 0.9\n",
        "\n",
        "        # train_on_batch recieves data and desired output\n",
        "        d_loss_fake = discriminator.train_on_batch(x[:batch_size], disc_y[:batch_size])\n",
        "        d_loss_real = discriminator.train_on_batch(x[batch_size:-1], disc_y[batch_size:-1])\n",
        "        # train GAN (descriminator weights are fixed)\n",
        "        y_gen = np.ones(batch_size)\n",
        "        g_loss = gan.train_on_batch(noise, y_gen)\n",
        "        # train reconstructor\n",
        "        r_loss = vae.train_on_batch(noise[:batch_size],noise[:batch_size])\n",
        "\n",
        "        \n",
        "\n",
        "    print(f'Epoch: {epoch} \\t Discriminator Loss: {(d_loss_fake+d_loss_real)/2} \\t\\t Generator Loss: {g_loss} \\t\\t Reconstructor Loss: {r_loss} ')\n",
        "\n",
        "\n",
        "def show_images(noise):\n",
        "    generated_images = generator.predict(noise)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    \n",
        "    for i, image in enumerate(generated_images):\n",
        "        plt.subplot(10, 10, i+1)\n",
        "        if channels == 1:\n",
        "            plt.imshow(image.reshape((img_rows, img_cols)), cmap='gray')\n",
        "        else:\n",
        "            plt.imshow(image.reshape((img_rows, img_cols, channels)))\n",
        "        plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "noise = np.random.normal(0, 1, size=(100, noise_dim))\n",
        "show_images(noise)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \t Discriminator Loss: 0.5041007995605469 \t\t Generator Loss: 3.208364248275757 \t\t Reconstructor Loss: 0.985313892364502 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-5-c4687d1e3ec6>\", line 25, in <module>\n",
            "    r_loss = vae.train_on_batch(noise[:batch_size],noise[:batch_size])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1449, in train_on_batch\n",
            "    outputs = self.train_function(ins)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2979, in __call__\n",
            "    return self._call(inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2937, in _call\n",
            "    fetched = self._callable_fn(*array_vals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
            "    module = self._load()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 44, in _load\n",
            "    module = _importlib.import_module(self.__name__)\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/__init__.py\", line 80, in <module>\n",
            "    from tensorflow.contrib import rpc\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rpc/__init__.py\", line 24, in <module>\n",
            "    from tensorflow.contrib.rpc.python.ops.rpc_op import rpc\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rpc/__init__.py\", line 24, in <module>\n",
            "    from tensorflow.contrib.rpc.python.ops.rpc_op import rpc\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 764, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 833, in get_data\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    }
  ]
}